import pandas as pd
import numpy as np
import torch
from sklearn.preprocessing import MinMaxScaler
import joblib  # Ù„Ø­ÙØ¸ Ø£Ø¯Ø§Ø© Ø§Ù„ØªÙ‚ÙŠÙŠØ³ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹

print("="*40)
print("âš™ï¸  STARTING DATA PROCESSING...")
print("="*40)

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ Ø­ÙØ¸Ù†Ø§Ù‡Ø§ Ø³Ø§Ø¨Ù‚Ø§Ù‹
df = pd.read_csv('PJME_hourly.csv', index_col='Datetime', parse_dates=True)
raw_data = df.values
print(f"ğŸ“š Original Data Loaded. Shape: {raw_data.shape}")

# 2. Ø§Ù„ØªÙ‚ÙŠÙŠØ³ (Normalization) - Ø¶ØºØ· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙŠÙ† 0 Ùˆ 1
# Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ø¬ÙˆÙ‡Ø±ÙŠØ© Ù„ØªØ³Ø±ÙŠØ¹ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©
scaler = MinMaxScaler(feature_range=(0, 1))
data_normalized = scaler.fit_transform(raw_data)

# Ø­ÙØ¸ Ø§Ù„Ù€ Scaler Ù„Ù†Ø³ØªØ®Ø¯Ù…Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ù„Ø¹ÙƒØ³ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© (Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©)
joblib.dump(scaler, 'scaler.pkl')
print("ğŸ“ Data Normalized & Scaler saved.")

# 3. Ø¯Ø§Ù„Ø© Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ù…Ù†Ø²Ù„Ù‚Ø© (Sliding Window Function)
def create_sequences(data, seq_length):
    xs = []
    ys = []
    for i in range(len(data) - seq_length):
        # Ù†Ø£Ø®Ø° Ù†Ø§ÙØ°Ø© Ø¨Ø­Ø¬Ù… seq_length (Ø§Ù„Ù…Ø§Ø¶ÙŠ)
        x = data[i:(i + seq_length)]
        # Ù†Ø£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØªÙŠ ØªÙ„ÙŠÙ‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© (Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„)
        y = data[i + seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

# Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù†Ø§ÙØ°Ø© Ø¨Ø­Ø¬Ù… 24 Ø³Ø§Ø¹Ø© (ÙŠÙˆÙ… ÙƒØ§Ù…Ù„) Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø³Ø§Ø¹Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
SEQ_LENGTH = 24
print(f"âœ‚ï¸  Slicing data into {SEQ_LENGTH}-hour sequences...")

X, y = create_sequences(data_normalized, SEQ_LENGTH)

# 4. Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø± (Train/Test Split)
# ØªØ­Ø°ÙŠØ± Ù‡Ø§Ù…: Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© (Shuffle) Ù…Ø¹ Ø§Ù„Ø²Ù…Ù†! ÙŠØ¬Ø¨ Ø£Ù† Ù†Ø­ØªØ±Ù… Ø§Ù„ØªØ±ØªÙŠØ¨.
train_size = int(len(X) * 0.8)  # 80% Ù„Ù„ØªØ¯Ø±ÙŠØ¨

X_train = X[:train_size]
y_train = y[:train_size]

X_test = X[train_size:]
y_test = y[train_size:]

# 5. Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ PyTorch Tensors (Ù„Ø£Ù† ÙƒØ±Øª Ø§Ù„Ø´Ø§Ø´Ø© ÙŠÙÙ‡Ù… Tensors ÙÙ‚Ø·)
# Ù†Ø­ØªØ§Ø¬ Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø´ÙƒÙ„ Ù„ÙŠÙƒÙˆÙ†: (Batch_Size, Sequence_Length, Features)
X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.float32)

print("-" * 30)
print("âœ… PROCESSING COMPLETE!")
print(f"ğŸ”¹ Training Data Shape: {X_train.shape}")
print(f"ğŸ”¹ Testing Data Shape:  {X_test.shape}")
print("-" * 30)

# Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù„Ø§Ø­Ù‚Ø§Ù‹
torch.save({'X_train': X_train, 'y_train': y_train, 
            'X_test': X_test, 'y_test': y_test}, 'processed_data.pt')
print("ğŸ’¾ Processed tensors saved to 'processed_data.pt'")